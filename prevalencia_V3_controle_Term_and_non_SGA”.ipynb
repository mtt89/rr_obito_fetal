{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71735b75-5149-49ab-8b9a-682ec047e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from Funcoes_auxiliares.func_aux import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181e7e2-49c4-49af-b4b0-3dd0faad0e76",
   "metadata": {},
   "source": [
    "# Carregando as bases e verificando os missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c659395a-269f-4812-864a-90d4b44aaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- carregar base SIM\n",
    "variaveis_sim_corte = ['SEMAGESTAC', 'idade_gestacao_faixa', 'PESO', 'peso_faixa', 'data_obito', 'SEXO', 'def_sexo', 'QTDFILMORT', 'QTDFILVIVO', 'def_paridade']\n",
    "df_sim = pd.read_csv('./base_suja/base_sim_dofet_suja_V2.csv',  usecols=variaveis_sim_corte)\n",
    "tamanho_sim_inicial=len(df_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1871ee6d-628d-4bbf-bf39-c9987c89195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9762563-9dac-450f-973d-dc49d3ce741d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Counting missing values\n",
    "# missing_count_sim_dofet = df_sim.isnull().sum()  # counts the null values in each column\n",
    "# missing_percent_sim_dofet = round((missing_count_sim_dofet / len(df_sim)) * 100,2)  # calculates the percentage of null values\n",
    "# missing_data_sim_dofet = pd.DataFrame({'Missing Count': missing_count_sim_dofet, 'Missing Percentage': missing_percent_sim_dofet})\n",
    "# missing_data_sim_dofet.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "# missing_data_sim_dofet.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "# missing_data_sim_dofet['BASE'] = 'SIM_DOFET'\n",
    "# # Sorting the DataFrame by the highest missing frequencies\n",
    "# missing_data_sorted = missing_data_sim_dofet.sort_values(by=['BASE', 'Missing Count'], ascending=False)\n",
    "# missing_data_sorted.to_csv('./EDA/missing_sim_dofet_v2.csv', index=False)\n",
    "# missing_data_sorted[missing_data_sorted['Missing Percentage'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58d32ab-5fe3-40e6-8f1d-e91837b373c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting ignorado values\n",
    "# ignorado_count_sim_dofet = df_sim.isin(['Ignorado', 'ignorado', 'IGNORADO']).sum()  # counts the null values in each column\n",
    "# ignorado_percent_sim_dofet = round((ignorado_count_sim_dofet / len(df_sim)) * 100,2)  # calculates the percentage of null values\n",
    "# ignorado_data_sim_dofet = pd.DataFrame({'Ignorado Count': ignorado_count_sim_dofet, 'Ignorado Percentage': ignorado_percent_sim_dofet})\n",
    "# ignorado_data_sim_dofet.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "# ignorado_data_sim_dofet.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "# ignorado_data_sim_dofet['BASE'] = 'SIM_DOFET'\n",
    "# # Sorting the DataFrame by the highest missing frequencies\n",
    "# ignorado_data_sorted = ignorado_data_sim_dofet.sort_values(by=['BASE', 'Ignorado Count'], ascending=False)\n",
    "# ignorado_data_sorted.to_csv('./EDA/ignorado_sim_dofet_v2.csv', index=False)\n",
    "# ignorado_data_sorted[ignorado_data_sorted['Ignorado Percentage'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308d01f8-3915-4a3d-abd9-2777ca5346b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar base SINASC\n",
    "variaveis_sinasc_corte = ['SEMAGESTAC', 'idade_gestacao_faixa', 'PESO', 'peso_faixa', 'data_nasc', 'SEXO', 'def_sexo', 'QTDFILMORT', 'QTDFILVIVO', 'def_paridade']\n",
    "df_sinasc = pd.read_csv('./base_suja/base_sinasc_suja_v2.csv',  usecols=variaveis_sinasc_corte)\n",
    "tamanho_sinasc_inicial=len(df_sinasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5020eb-31f1-48b2-a6da-2e91d824aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sinasc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10bb0189-1c84-4d0a-89af-a555fa59fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_count_sinasc = df_sinasc.isnull().sum()  # counts the null values in each column\n",
    "# missing_percent_sinasc = round((missing_count_sinasc / len(df_sinasc)) * 100,2)  # calculates the percentage of null values\n",
    "# missing_data_sinasc = pd.DataFrame({'Missing Count': missing_count_sinasc, 'Missing Percentage': missing_percent_sinasc})\n",
    "# missing_data_sinasc.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "# missing_data_sinasc.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "# missing_data_sinasc['BASE'] = 'SINASC'\n",
    "# \n",
    "# # Sorting the DataFrame by the highest missing frequencies\n",
    "# missing_data_sorted = missing_data_sinasc.sort_values(by=['BASE', 'Missing Count'], ascending=False)\n",
    "# missing_data_sorted.to_csv('./EDA/missing_sinasc_v2.csv', index=False)\n",
    "# missing_data_sorted[missing_data_sorted['Missing Percentage'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc383ed0-a386-46f5-8d91-5c400dcdb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Counting ignorado values\n",
    "# ignorado_count_sinasc = df_sinasc.isin(['Ignorado', 'ignorado', 'IGNORADO']).sum()  # counts the null values in each column\n",
    "# ignorado_percent_sinasc = round((ignorado_count_sinasc / len(df_sinasc)) * 100,2)  # calculates the percentage of null values\n",
    "# ignorado_data_sinasc = pd.DataFrame({'Ignorado Count': ignorado_count_sinasc, 'Ignorado Percentage': ignorado_percent_sinasc})\n",
    "# ignorado_data_sinasc.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "# ignorado_data_sinasc.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "# ignorado_data_sinasc['BASE'] = 'SINASC'\n",
    "# # Sorting the DataFrame by the highest missing frequencies\n",
    "# ignorado_data_sorted = ignorado_data_sinasc.sort_values(by=['BASE', 'Ignorado Count'], ascending=False)\n",
    "# ignorado_data_sorted.to_csv('./EDA/ignorado_sinasc_v2.csv', index=False)\n",
    "# ignorado_data_sorted[ignorado_data_sorted['Ignorado Percentage'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cda42b-644c-41e7-ac06-c05bee2f506a",
   "metadata": {},
   "source": [
    "# Limpezas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f5979d-520c-472a-ba87-2bd6730acdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31909 observações removidas Sim. 1726144 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Remover os Missings sim e sinasc\n",
    "var_sim_missing = 'QTDFILMORT'\n",
    "var_sinasc_missing = 'QTDFILMORT'\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim[var_sim_missing].isnull()].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc[var_sinasc_missing].isnull()].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3f31b2-e8cf-4b3d-986c-f1c92176bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610 observações removidas Sim. 92486 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Remover os Missings sim e sinasc\n",
    "var_sim_missing = 'QTDFILVIVO'\n",
    "var_sinasc_missing = 'QTDFILVIVO'\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim[var_sim_missing].isnull()].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc[var_sinasc_missing].isnull()].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17cb5614-66af-410c-a1ff-8308e2eed324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946 observações removidas Sim. 1771 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Remoção 'Ignorados'\n",
    "var_sim_ign = 'def_paridade'\n",
    "var_sinasc_ign = 'def_paridade'\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim[var_sim_ign].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc[var_sinasc_ign].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17cf505a-f20d-40c7-8f35-358ea264ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9430 observações removidas Sim. 433982 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpar Missing SEMANAGESTAC\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['SEMAGESTAC'].isnull()].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['SEMAGESTAC'].isnull()].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bd33302-6454-443a-b5a5-1070c15cbbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3979 observações removidas Sim. 235230 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpeza Ignorado\n",
    "# Limpar 'idade_gestacao_faixa'\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['idade_gestacao_faixa'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['idade_gestacao_faixa'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b674727-f7d1-41b2-91be-6e613fa0bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 observações removidas Sim. 0 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpar Missing SEXO\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['SEXO'].isnull()].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['SEXO'].isnull()].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62fb1f1f-a4fc-4e2a-b044-ffed4f3fd394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6165 observações removidas Sim. 4305 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpeza Ignorado\n",
    "# Limpar def_sexo\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['def_sexo'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['def_sexo'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c8ab4f-e1e7-4b9b-9f1f-153f54dccfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9141 observações removidas Sim. 5611 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpar Missing PESO\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['PESO'].isnull()].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['PESO'].isnull()].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463bdaf9-7ac0-4e8e-8478-0a3d508b3e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 observações removidas Sim. 0 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpeza Ignorado\n",
    "# Limpar 'peso_faixa'\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['peso_faixa'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['peso_faixa'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc843e43-64e0-483c-b62e-5ec917070bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_peso_calc(sexo, peso, semana):\n",
    "    # Se algum argumento essencial for nulo, retorna np.nan\n",
    "    if pd.isna(sexo) or pd.isna(peso) or pd.isna(semana):\n",
    "        return np.nan\n",
    "    # Caso contrário, chama a função original\n",
    "    return func_peso_calculado(sexo, peso, int(round(semana)))\n",
    "\n",
    "df_sim['cat_peso_calc'] = [\n",
    "    safe_peso_calc(sexo, peso, semana)\n",
    "    for sexo, peso, semana in zip(\n",
    "        df_sim['SEXO'],\n",
    "        df_sim['PESO'],\n",
    "        df_sim['SEMAGESTAC']\n",
    "    )\n",
    "]\n",
    "df_sinasc['cat_peso_calc'] = [\n",
    "    safe_peso_calc(sexo, peso, semana)\n",
    "    for sexo, peso, semana in zip(\n",
    "        df_sinasc['SEXO'],\n",
    "        df_sinasc['PESO'],\n",
    "        df_sinasc['SEMAGESTAC']\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9db45318-7c9d-42b6-8510-1f32c4292f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 observações removidas Sim. 0 observações removidas Sinasc.\n"
     ]
    }
   ],
   "source": [
    "# Limpar peso calculado\n",
    "tamanho_antes_sim, tamanho_antes_sinasc = len(df_sim), len(df_sinasc)\n",
    "df_sim = df_sim[~df_sim['cat_peso_calc'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "df_sinasc = df_sinasc[~df_sinasc['cat_peso_calc'].isin(['Ignorado', 'ignorado', 'IGNORADO'])].reset_index(drop=True)\n",
    "tamanho_depois_sim, tamanho_depois_sinasc = len(df_sim), len(df_sinasc)\n",
    "print(f'{tamanho_antes_sim - tamanho_depois_sim} observações removidas Sim. {tamanho_antes_sinasc - tamanho_depois_sinasc} observações removidas Sinasc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edb7f8e5-cd78-4623-8cda-7a5e42ac2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando os campos após as limpezas\n",
    "df_sim['cat_peso_calc_2'] = ['PIG' if i=='PIG' else 'NAO_PIG' for i in df_sim['cat_peso_calc']]\n",
    "df_sim['cat_periodo_nasc'] = ['termo' if sem >= 37 else 'pre_termo' for sem in df_sim['SEMAGESTAC']]\n",
    "df_sinasc['cat_peso_calc_2'] = ['PIG' if i=='PIG' else 'NAO_PIG' for i in df_sinasc['cat_peso_calc']]\n",
    "df_sinasc['cat_periodo_nasc'] = ['termo' if sem >= 37 else 'pre_termo' for sem in df_sinasc['SEMAGESTAC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f69efac9-62b1-43ca-b125-c1776700bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69180 observações totais removidas Sim, sobrou 234277 obs.\n",
      "2499529 observações totais removidas Sinasc, sobrou 25946006 obs.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"{tamanho_sim_inicial - len(df_sim)} observações totais removidas Sim, sobrou {len(df_sim)} obs.\n",
    "{tamanho_sinasc_inicial - len(df_sinasc)} observações totais removidas Sinasc, sobrou {len(df_sinasc)} obs.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea69148-0f67-41a7-a902-5fcfad9148b2",
   "metadata": {},
   "source": [
    "# Gerar Prevalência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4bec846-5dc8-44e3-8c8f-259ca04cbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURAÇÃO DA VARIÁVEL DE INTERESSE\n",
    "# ============================================\n",
    "\n",
    "# Nome da variável no SINASC (denominador)\n",
    "VAR_SINASC = 'def_paridade'      # ex: 'nasc_REGIAO', 'cat_escolaridade_mae', 'cat_idade_mae'\n",
    "\n",
    "# Nome da variável no SIM (numerador)\n",
    "VAR_SIM = 'def_paridade'        # ex: 'ocor_REGIAO', 'cat_escolaridade_mae', 'cat_idade_mae'\n",
    "\n",
    "# Nome amigável que vai aparecer na tabela final\n",
    "NOME_GRUPO = 'Paridade'             # ex: 'Region', 'Escolaridade da mãe', 'Idade materna'\n",
    "\n",
    "# Escala da prevalência de óbitos: 100 = por 100 NV, 1000 = por 1.000 NV\n",
    "SCALE = 1000.0\n",
    "\n",
    "# Número de casas decimais para a prevalência\n",
    "DECIMALS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57dad8a0-d821-4ac8-abf4-2b3298c3ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Rotulagem das categorias SVN (pré-termo/termo x SGA/non-SGA)\n",
    "# --------------------------------------------------\n",
    "pretty_map = {\n",
    "    ('pre_termo', 'PIG'): 'Preterm and SGA',\n",
    "    ('pre_termo', 'NAO_PIG'): 'Preterm non-SGA',\n",
    "    ('termo', 'PIG'): 'Term and SGA',\n",
    "    ('termo', 'NAO_PIG'): 'Term and non-SGA'\n",
    "}\n",
    "\n",
    "def label_cat(row):\n",
    "    t = (row['cat_periodo_nasc'], row['cat_peso_calc_2'])\n",
    "    return pretty_map.get(t, f\"{row['cat_periodo_nasc']} & {row['cat_peso_calc_2']}\")\n",
    "\n",
    "def is_term_non_sga(cat_name: str) -> bool:\n",
    "    name = (cat_name or \"\").lower()\n",
    "    return 'term' in name and 'non' in name and 'sga' in name\n",
    "    \n",
    "# --------------------------------------------------\n",
    "# Prevalência + IC95% (Wald)\n",
    "# --------------------------------------------------\n",
    "def prev_ci_wald(n_events, n_total, scale=1000.0, k=1.96, decimals=2):\n",
    "    if n_total <= 0:\n",
    "        return np.nan, np.nan, np.nan, \"\"\n",
    "    p = n_events / n_total\n",
    "    se = np.sqrt(p * (1 - p) / n_total)\n",
    "    lo = max(p - k * se, 0)\n",
    "    hi = min(p + k * se, 1)\n",
    "    txt = f\"{(p*scale):.{decimals}f} ({(lo*scale):.{decimals}f}-{(hi*scale):.{decimals}f})\"\n",
    "    return p, lo, hi, txt\n",
    "\n",
    "def pvalue_vs_term_non_sga(n_deaths_group, n_births_group,\n",
    "                           n_deaths_ref,   n_births_ref):\n",
    "    \"\"\"\n",
    "    Compara grupo vs Term and non-SGA.\n",
    "    Teste z para duas proporções independentes.\n",
    "    \"\"\"\n",
    "    if n_births_group == 0 or n_births_ref == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    p1 = n_deaths_group / n_births_group\n",
    "    p0 = n_deaths_ref   / n_births_ref\n",
    "\n",
    "    se = np.sqrt(\n",
    "        p0 * (1 - p0) / n_births_ref +\n",
    "        p1 * (1 - p1) / n_births_group\n",
    "    )\n",
    "\n",
    "    if se == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    z = (p1 - p0) / se\n",
    "    p = 2 * (1 - norm.cdf(abs(z)))\n",
    "    return p\n",
    "\n",
    "def fmt_p(p):\n",
    "    if pd.isna(p):\n",
    "        return ''\n",
    "    return '<0.001' if p < 0.001 else f'{p:.3f}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39aad28b-d671-4204-a57f-dda3fe2e9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_prevalencia_obitos_generico(df_sinasc, df_sim,\n",
    "                                        var_sinasc=VAR_SINASC,\n",
    "                                        var_sim=VAR_SIM,\n",
    "                                        nome_grupo=NOME_GRUPO,\n",
    "                                        scale=SCALE,\n",
    "                                        decimals=DECIMALS):\n",
    "    \"\"\"\n",
    "    Calcula prevalência de óbitos por categoria SVN e por variável de interesse (grupo),\n",
    "    com IC95% e p-valor (grupo vs Brasil), incluindo:\n",
    "      - NV e óbitos por categoria/grupo\n",
    "      - total de NV e óbitos por grupo\n",
    "    \"\"\"\n",
    "\n",
    "    # =========================\n",
    "    # 1) Agregados REGIONAIS (por grupo de interesse)\n",
    "    # =========================\n",
    "    sim_reg = (df_sim\n",
    "               .groupby([var_sim, 'cat_periodo_nasc', 'cat_peso_calc_2'])\n",
    "               .agg(obitos_reg_cat=('data_obito', 'size'))\n",
    "               .reset_index())\n",
    "    sim_reg['SVN_cat'] = sim_reg.apply(label_cat, axis=1)\n",
    "    sim_reg = sim_reg.rename(columns={var_sim: 'GRUPO'})\n",
    "\n",
    "    sinasc_reg = (df_sinasc\n",
    "                  .groupby([var_sinasc, 'cat_periodo_nasc', 'cat_peso_calc_2'])\n",
    "                  .agg(nasc_reg_cat=('data_nasc', 'size'))\n",
    "                  .reset_index())\n",
    "    sinasc_reg['SVN_cat'] = sinasc_reg.apply(label_cat, axis=1)\n",
    "    sinasc_reg = sinasc_reg.rename(columns={var_sinasc: 'GRUPO'})\n",
    "\n",
    "    # =========================\n",
    "    # 2) Agregados BRASIL (somando todos os grupos)\n",
    "    # =========================\n",
    "    sim_br = (df_sim\n",
    "              .groupby(['cat_periodo_nasc', 'cat_peso_calc_2'])\n",
    "              .agg(obitos_br_cat=('data_obito', 'size'))\n",
    "              .reset_index())\n",
    "    sim_br['SVN_cat'] = sim_br.apply(label_cat, axis=1)\n",
    "\n",
    "    sinasc_br = (df_sinasc\n",
    "                 .groupby(['cat_periodo_nasc', 'cat_peso_calc_2'])\n",
    "                 .agg(nasc_br_cat=('data_nasc', 'size'))\n",
    "                 .reset_index())\n",
    "    sinasc_br['SVN_cat'] = sinasc_br.apply(label_cat, axis=1)\n",
    "\n",
    "    br = (sim_br[['SVN_cat','obitos_br_cat']]\n",
    "          .merge(sinasc_br[['SVN_cat','nasc_br_cat']], on='SVN_cat', how='outer')\n",
    "          .fillna(0))\n",
    "    br['obitos_br_cat'] = br['obitos_br_cat'].astype(int)\n",
    "    br['nasc_br_cat'] = br['nasc_br_cat'].astype(int)\n",
    "    br['p_br'] = np.where(br['nasc_br_cat'] > 0,\n",
    "                          br['obitos_br_cat'] / br['nasc_br_cat'],\n",
    "                          np.nan)\n",
    "\n",
    "    # =========================\n",
    "    # 3) Grade completa (todas combinações grupo x categoria)\n",
    "    # =========================\n",
    "    all_groups = sorted(sinasc_reg['GRUPO'].unique().tolist())\n",
    "    all_cats = sorted(\n",
    "        set(sim_reg['SVN_cat'].unique()).union(set(sinasc_reg['SVN_cat'].unique()))\n",
    "    )\n",
    "\n",
    "    grid = pd.MultiIndex.from_product([all_groups, all_cats],\n",
    "                                      names=['GRUPO','SVN_cat']).to_frame(index=False)\n",
    "\n",
    "    reg = (grid\n",
    "           .merge(sim_reg[['GRUPO','SVN_cat','obitos_reg_cat']], on=['GRUPO','SVN_cat'], how='left')\n",
    "           .merge(sinasc_reg[['GRUPO','SVN_cat','nasc_reg_cat']], on=['GRUPO','SVN_cat'], how='left'))\n",
    "\n",
    "    reg['obitos_reg_cat'] = reg['obitos_reg_cat'].fillna(0).astype(int)\n",
    "    reg['nasc_reg_cat'] = reg['nasc_reg_cat'].fillna(0).astype(int)\n",
    "\n",
    "    # junta p_br\n",
    "    reg = reg.merge(br[['SVN_cat','p_br']], on='SVN_cat', how='left')\n",
    "\n",
    "    # =========================\n",
    "    # 4) Calcula prevalência, IC95% e p-valor por grupo x categoria\n",
    "    # =========================\n",
    "    linhas = []\n",
    "    REF = \"Term and non-SGA\"\n",
    "    # 'reg' deve ter colunas: 'GRUPO', 'SVN_cat', 'obitos_reg_cat', 'nasc_reg_cat'\n",
    "    \n",
    "    for (g, cat), row in reg.set_index(['GRUPO', 'SVN_cat']).iterrows():\n",
    "        n_deaths = int(row['obitos_reg_cat'])\n",
    "        n_births = int(row['nasc_reg_cat'])\n",
    "    \n",
    "        # 1) Prevalência + IC95% (Wald)\n",
    "        p_reg, ci_low, ci_high, prev_txt = prev_ci_wald(\n",
    "            n_events=n_deaths,\n",
    "            n_total=n_births,\n",
    "            scale=SCALE,\n",
    "            decimals=DECIMALS\n",
    "        )\n",
    "    \n",
    "        # 2) p-valor: comparação com Term and non-SGA DENTRO DO MESMO GRUPO g\n",
    "        if cat == REF:\n",
    "            # grupo de referência fisiológico -> sem p-valor\n",
    "            pval_fmt = ''\n",
    "        else:\n",
    "            # tenta localizar a linha de referência (mesmo grupo g, SVN_cat = REF)\n",
    "            ref_mask = (reg['GRUPO'] == g) & (reg['SVN_cat'] == REF)\n",
    "            if not ref_mask.any():\n",
    "                # se não existir Term and non-SGA naquele grupo, não calcula p-valor\n",
    "                pval_fmt = ''\n",
    "            else:\n",
    "                ref_row = reg.loc[ref_mask].iloc[0]\n",
    "                n_deaths_ref = int(ref_row['obitos_reg_cat'])\n",
    "                n_births_ref = int(ref_row['nasc_reg_cat'])\n",
    "    \n",
    "                pval = pvalue_vs_term_non_sga(\n",
    "                    n_deaths_group=n_deaths,\n",
    "                    n_births_group=n_births,\n",
    "                    n_deaths_ref=n_deaths_ref,\n",
    "                    n_births_ref=n_births_ref\n",
    "                )\n",
    "                pval_fmt = fmt_p(pval)\n",
    "    \n",
    "        linhas.append({\n",
    "            nome_grupo: g,                  # ex.: 'Region', 'Escolaridade da mãe'\n",
    "            'SVN_cat': cat,\n",
    "            'Prev % (95% CI)': prev_txt,\n",
    "            'p-value': pval_fmt,\n",
    "            'NV (cat, grupo)': n_births,\n",
    "            'Óbitos (cat, grupo)': n_deaths\n",
    "        })\n",
    "    \n",
    "    long_reg = pd.DataFrame(linhas)\n",
    "    # =========================\n",
    "    # 5) Linha BRASIL\n",
    "    # =========================\n",
    "    # 'br' deve ter: 'SVN_cat', 'obitos_br_cat', 'nasc_br_cat'\n",
    "    linhas_br = []\n",
    "    \n",
    "    for _, r in br.iterrows():\n",
    "        cat = r['SVN_cat']\n",
    "        n_deaths_br = int(r['obitos_br_cat'])\n",
    "        n_births_br = int(r['nasc_br_cat'])\n",
    "    \n",
    "        p_br, ci_low_br, ci_high_br, prev_txt_br = prev_ci_wald(\n",
    "            n_events=n_deaths_br,\n",
    "            n_total=n_births_br,\n",
    "            scale=SCALE,\n",
    "            decimals=DECIMALS\n",
    "        )\n",
    "    \n",
    "        linhas_br.append({\n",
    "            nome_grupo: 'Brasil',\n",
    "            'SVN_cat': cat,\n",
    "            'Prev % (95% CI)': prev_txt_br,\n",
    "            'p-value': '',                    # Brasil agora é só descritivo\n",
    "            'NV (cat, grupo)': n_births_br,\n",
    "            'Óbitos (cat, grupo)': n_deaths_br\n",
    "        })\n",
    "    \n",
    "    long_br = pd.DataFrame(linhas_br)\n",
    "    \n",
    "    # Junta grupos + Brasil\n",
    "    long_final = pd.concat([long_reg, long_br], ignore_index=True)\n",
    "\n",
    "    # =========================\n",
    "    # 6) Monta tabela larga (uma coluna por categoria)\n",
    "    # =========================\n",
    "    # ordem de categorias (usa pretty_map quando possível)\n",
    "    base_order = list(pretty_map.values())\n",
    "    cats_order = [c for c in base_order if c in long_final['SVN_cat'].unique()] + \\\n",
    "                 [c for c in long_final['SVN_cat'].unique() if c not in base_order]\n",
    "\n",
    "    wide_parts = []\n",
    "    for cat in cats_order:\n",
    "        sub = long_final[long_final['SVN_cat'] == cat].copy()\n",
    "        sub = sub.rename(columns={\n",
    "            'Prev % (95% CI)': f'{cat} % (95% CI)',\n",
    "            'p-value': f'{cat} p-value',\n",
    "            'NV (cat, grupo)': f'{cat} NV',\n",
    "            'Óbitos (cat, grupo)': f'{cat} Óbitos'\n",
    "        })\n",
    "\n",
    "        if is_term_non_sga(cat):\n",
    "            sub[f'{cat} p-value'] = ''\n",
    "\n",
    "        sub = sub[[nome_grupo,\n",
    "                   f'{cat} % (95% CI)',\n",
    "                   f'{cat} p-value',\n",
    "                   f'{cat} NV',\n",
    "                   f'{cat} Óbitos']]\n",
    "        wide_parts.append(sub)\n",
    "\n",
    "    tabela = wide_parts[0]\n",
    "    for part in wide_parts[1:]:\n",
    "        tabela = tabela.merge(part, on=nome_grupo, how='outer')\n",
    "\n",
    "    # Totais NV e óbitos por grupo\n",
    "    tot_nv = (sinasc_reg.groupby('GRUPO')['nasc_reg_cat']\n",
    "                        .sum()\n",
    "                        .rename('N nascidos vivos (grupo)')\n",
    "                        .reset_index()\n",
    "                        .rename(columns={'GRUPO': nome_grupo}))\n",
    "\n",
    "    tot_obitos = (long_final.groupby(nome_grupo)['Óbitos (cat, grupo)']\n",
    "                             .sum()\n",
    "                             .rename('Óbitos totais (grupo)')\n",
    "                             .reset_index())\n",
    "\n",
    "    tabela = (tabela\n",
    "              .merge(tot_nv, on=nome_grupo, how='left')\n",
    "              .merge(tot_obitos, on=nome_grupo, how='left'))\n",
    "\n",
    "    # Ordenar e jogar Brasil pra última linha\n",
    "    tabela = tabela.sort_values(by=nome_grupo)\n",
    "    if 'Brasil' in tabela[nome_grupo].values:\n",
    "        br_row = tabela[tabela[nome_grupo] == 'Brasil']\n",
    "        tabela = pd.concat([tabela[tabela[nome_grupo] != 'Brasil'], br_row], ignore_index=True)\n",
    "\n",
    "    return tabela, long_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3164ae6-65e8-4c88-9d64-72e95df64fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paridade</th>\n",
       "      <th>Preterm and SGA % (95% CI)</th>\n",
       "      <th>Preterm and SGA p-value</th>\n",
       "      <th>Preterm and SGA NV</th>\n",
       "      <th>Preterm and SGA Óbitos</th>\n",
       "      <th>Preterm non-SGA % (95% CI)</th>\n",
       "      <th>Preterm non-SGA p-value</th>\n",
       "      <th>Preterm non-SGA NV</th>\n",
       "      <th>Preterm non-SGA Óbitos</th>\n",
       "      <th>Term and SGA % (95% CI)</th>\n",
       "      <th>Term and SGA p-value</th>\n",
       "      <th>Term and SGA NV</th>\n",
       "      <th>Term and SGA Óbitos</th>\n",
       "      <th>Term and non-SGA % (95% CI)</th>\n",
       "      <th>Term and non-SGA p-value</th>\n",
       "      <th>Term and non-SGA NV</th>\n",
       "      <th>Term and non-SGA Óbitos</th>\n",
       "      <th>N nascidos vivos (grupo)</th>\n",
       "      <th>Óbitos totais (grupo)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multiparous</td>\n",
       "      <td>156.56 (155.34-157.77)</td>\n",
       "      <td>&lt;0.001</td>\n",
       "      <td>342368</td>\n",
       "      <td>53600</td>\n",
       "      <td>48.80 (48.46-49.15)</td>\n",
       "      <td></td>\n",
       "      <td>1497830</td>\n",
       "      <td>73097</td>\n",
       "      <td>7.49 (7.38-7.61)</td>\n",
       "      <td>&lt;0.001</td>\n",
       "      <td>2139696</td>\n",
       "      <td>16036</td>\n",
       "      <td>2.13 (2.11-2.16)</td>\n",
       "      <td></td>\n",
       "      <td>12067841</td>\n",
       "      <td>25733</td>\n",
       "      <td>16047735.0</td>\n",
       "      <td>168466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primiparous</td>\n",
       "      <td>84.28 (83.22-85.35)</td>\n",
       "      <td>&lt;0.001</td>\n",
       "      <td>262577</td>\n",
       "      <td>22131</td>\n",
       "      <td>32.15 (31.78-32.52)</td>\n",
       "      <td></td>\n",
       "      <td>883714</td>\n",
       "      <td>28412</td>\n",
       "      <td>3.87 (3.78-3.96)</td>\n",
       "      <td>&lt;0.001</td>\n",
       "      <td>1734125</td>\n",
       "      <td>6708</td>\n",
       "      <td>1.22 (1.19-1.25)</td>\n",
       "      <td></td>\n",
       "      <td>7017855</td>\n",
       "      <td>8560</td>\n",
       "      <td>9898271.0</td>\n",
       "      <td>65811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>125.19 (124.35-126.02)</td>\n",
       "      <td></td>\n",
       "      <td>604945</td>\n",
       "      <td>75731</td>\n",
       "      <td>42.62 (42.37-42.88)</td>\n",
       "      <td></td>\n",
       "      <td>2381544</td>\n",
       "      <td>101509</td>\n",
       "      <td>5.87 (5.80-5.95)</td>\n",
       "      <td></td>\n",
       "      <td>3873821</td>\n",
       "      <td>22744</td>\n",
       "      <td>1.80 (1.78-1.82)</td>\n",
       "      <td></td>\n",
       "      <td>19085696</td>\n",
       "      <td>34293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Paridade Preterm and SGA % (95% CI) Preterm and SGA p-value  \\\n",
       "0  Multiparous     156.56 (155.34-157.77)                  <0.001   \n",
       "1  Primiparous        84.28 (83.22-85.35)                  <0.001   \n",
       "2       Brasil     125.19 (124.35-126.02)                           \n",
       "\n",
       "   Preterm and SGA NV  Preterm and SGA Óbitos Preterm non-SGA % (95% CI)  \\\n",
       "0              342368                   53600        48.80 (48.46-49.15)   \n",
       "1              262577                   22131        32.15 (31.78-32.52)   \n",
       "2              604945                   75731        42.62 (42.37-42.88)   \n",
       "\n",
       "  Preterm non-SGA p-value  Preterm non-SGA NV  Preterm non-SGA Óbitos  \\\n",
       "0                                     1497830                   73097   \n",
       "1                                      883714                   28412   \n",
       "2                                     2381544                  101509   \n",
       "\n",
       "  Term and SGA % (95% CI) Term and SGA p-value  Term and SGA NV  \\\n",
       "0        7.49 (7.38-7.61)               <0.001          2139696   \n",
       "1        3.87 (3.78-3.96)               <0.001          1734125   \n",
       "2        5.87 (5.80-5.95)                               3873821   \n",
       "\n",
       "   Term and SGA Óbitos Term and non-SGA % (95% CI) Term and non-SGA p-value  \\\n",
       "0                16036            2.13 (2.11-2.16)                            \n",
       "1                 6708            1.22 (1.19-1.25)                            \n",
       "2                22744            1.80 (1.78-1.82)                            \n",
       "\n",
       "   Term and non-SGA NV  Term and non-SGA Óbitos  N nascidos vivos (grupo)  \\\n",
       "0             12067841                    25733                16047735.0   \n",
       "1              7017855                     8560                 9898271.0   \n",
       "2             19085696                    34293                       NaN   \n",
       "\n",
       "   Óbitos totais (grupo)  \n",
       "0                 168466  \n",
       "1                  65811  \n",
       "2                 234277  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela, long_tab = calcula_prevalencia_obitos_generico(\n",
    "    df_sinasc=df_sinasc,\n",
    "    df_sim=df_sim,\n",
    "    var_sinasc=VAR_SINASC,\n",
    "    var_sim=VAR_SIM,\n",
    "    nome_grupo=NOME_GRUPO,\n",
    "    scale=SCALE\n",
    ")\n",
    "tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5031f372-bb79-4751-ab61-997435472bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 8) Resultado\n",
    "# =========================\n",
    "# print(\"Prevalência de óbitos por categoria SVN (por {:.0f} NV), IC95% e p-valor (Região vs Brasil):\".format(SCALE))\n",
    "# print(tabela)\n",
    "# Se quiser salvar para Excel/CSV:\n",
    "tabela.to_excel(f'./resultado_prevalencia/prevalencia_obitos_por_categoria_{NOME_GRUPO}_v3.xlsx', index=False)\n",
    "# tabela.to_csv('prevalencia_obitos_por_categoria_regiao.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18246e3-4d8f-4ac4-bb8d-109284eb0432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
