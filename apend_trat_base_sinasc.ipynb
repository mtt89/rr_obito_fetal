{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Funcoes_auxiliares.func_aux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obito_parto(cod):\n",
    "    if cod == 1:\n",
    "        return 'Antes'\n",
    "    elif cod == 2:\n",
    "        return 'Durante'\n",
    "    elif cod == 3:\n",
    "        return 'Depois'\n",
    "    else:\n",
    "         return 'Ignorado'\n",
    "\n",
    "def estado_civil(cod):\n",
    "    if cod == 1:\n",
    "        return 'Solteiro'\n",
    "    elif cod == 2:\n",
    "        return 'Casado'\n",
    "    elif cod == 3:\n",
    "        return 'Viuvo'\n",
    "    elif cod == 4:\n",
    "        return 'Separado_judicialmente'\n",
    "    elif cod == 5:\n",
    "        return 'Uniao_consensual'\n",
    "    else:\n",
    "         return 'Ignorado'\n",
    "        \n",
    "def raca_cor(cod):\n",
    "    if cod == 1:\n",
    "        return 'Branca'\n",
    "    elif cod == 2:\n",
    "        return 'Preta'\n",
    "    elif cod == 3:\n",
    "        return 'Amarela'\n",
    "    elif cod == 4:\n",
    "        return 'Parda'\n",
    "    elif cod == 5:\n",
    "        return 'Indigena'\n",
    "    else:\n",
    "         return 'Ignorado'\n",
    "\n",
    "def paridade(cod):\n",
    "    if cod == 0.0:\n",
    "        return 'Primiparous'\n",
    "    elif (cod > 0.0) & (cod <= 98.0):\n",
    "        return 'Multiparous'\n",
    "    else:\n",
    "         return 'Ignorado'\n",
    "\n",
    "def func_categorize_gravidez(cod_grav):\n",
    "    if cod_grav == 1:\n",
    "        return \"Unica\"\n",
    "    elif 2 <= cod_grav <= 3:\n",
    "        return \"Multipla\"\n",
    "    else:\n",
    "        return \"Ignorado\"\n",
    "\n",
    "def func_obito_parto(cod):\n",
    "    if cod == 1:\n",
    "        return \"Antes\"\n",
    "    elif cod == 2:\n",
    "        return \"Durante\"\n",
    "    elif cod == 3:\n",
    "        return \"Depois\"\n",
    "    else:\n",
    "        return \"Ignorado\"\n",
    "        \n",
    "def func_parto(cod):\n",
    "    if cod == 1:\n",
    "        return \"Vaginal\"\n",
    "    elif cod == 2:\n",
    "        return \"Cesareo\"\n",
    "    else:\n",
    "        return \"Ignorado\"\n",
    "\n",
    "def safe_peso_calc(sexo, peso, semana):\n",
    "    # Se algum argumento essencial for nulo, retorna np.nan\n",
    "    if pd.isna(sexo) or pd.isna(peso) or pd.isna(semana):\n",
    "        return np.nan\n",
    "    # Caso contrário, chama a função original\n",
    "    return func_peso_calculado(sexo, peso, int(round(semana)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasta_origem = r\"D:/ETLSINASC\"\n",
    "year =[2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_list_path_files(path: str):\n",
    "    \"\"\"\n",
    "    Maps files to a specified path\n",
    "    :param path (str): Path of the folder that should be mapped\n",
    "    :return: Returns a list with the path of all files in the folder.\n",
    "    \"\"\"\n",
    "    arquivos = []\n",
    "    for diretorio_raiz, _, arquivos_na_pasta in os.walk(path):\n",
    "        for arquivo in arquivos_na_pasta:\n",
    "            endereco_completo = os.path.join(diretorio_raiz, arquivo)\n",
    "            arquivos.append(endereco_completo)\n",
    "    return arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_arq = function_list_path_files(path=pasta_origem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter addresses according to the years of interest\n",
    "enderecos_filtrados = [endereco for endereco in lista_arq if any(str(ano) in endereco for ano in year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis = [\n",
    "    'data_nasc'\n",
    "    , 'ano_nasc'\n",
    "    , 'nasc_MUNNOMEX' #'ocor_MUNNOMEX'\n",
    "    , 'res_MUNNOMEX'\n",
    "    , 'nasc_CAPITAL'\n",
    "    , 'res_CAPITAL'\n",
    "    , 'nasc_REGIAO'\n",
    "    , 'res_REGIAO'\n",
    "    , 'nasc_SIGLA_UF'\n",
    "    , 'res_SIGLA_UF'\n",
    "    , 'IDADEMAE'\n",
    "    , 'ESCMAE2010'\n",
    "    , 'GRAVIDEZ'\n",
    "    , 'SEMAGESTAC'\n",
    "    , 'SEXO'\n",
    "    , 'def_sexo'\n",
    "    , 'PESO'\n",
    "   # , 'OBITOPARTO'\n",
    "    , 'ESTCIVMAE'\n",
    "    , 'RACACOR'\n",
    "    , 'QTDFILMORT'\n",
    "    , 'QTDFILVIVO'\n",
    "    , 'PARTO'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (30,112,113,114,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (25,114,115,116,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (30,112,113,114,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (30,112,113,114,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (24,114,115,116,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n",
      "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_8716\\3998216533.py:1: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]\n"
     ]
    }
   ],
   "source": [
    "df = [pd.read_csv(i)[variaveis] for i in enderecos_filtrados]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc = pd.concat(df_sinasc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc['FLAG_BASE'] = 'SINASC'\n",
    "df_sinasc['idademae_faixa'] = [func_categorize_idademae(i) for i in df_sinasc['IDADEMAE']]\n",
    "df_sinasc['escolaridade_mae'] = [func_categorize_escolmae(i) for i in df_sinasc['ESCMAE2010']]\n",
    "df_sinasc['tipo_gravidez'] = [func_categorize_gravidez(i) for i in df_sinasc['GRAVIDEZ']]\n",
    "df_sinasc['idade_gestacao_faixa'] = [func_categorize_idade_gest(i) for i in df_sinasc['SEMAGESTAC']]\n",
    "df_sinasc['peso_faixa'] = [func_categorize_peso(i) for i in df_sinasc['PESO']]\n",
    "# df_sinasc['def_obito_parto'] = [obito_parto(cod) for cod in  df_sinasc['OBITOPARTO']]\n",
    "df_sinasc['def_est_civil'] = [estado_civil(i) for i in df_sinasc['ESTCIVMAE']]\n",
    "df_sinasc['def_raca_cor'] = [raca_cor(i) for i in df_sinasc['RACACOR']]\n",
    "df_sinasc['def_paridade'] = [paridade(cod=i+j) for i, j in zip(df_sinasc['QTDFILMORT'], df_sinasc['QTDFILVIVO'])]\n",
    "df_sinasc['tipo_gravidez'] = [func_categorize_gravidez(i) for i in df_sinasc['GRAVIDEZ']]\n",
    "# df_sinasc['def_obito_parto'] = [func_obito_parto(i) for i in df_sinasc['OBITOPARTO']]\n",
    "df_sinasc['def_parto'] = [func_parto(i) for i in df_sinasc['PARTO']]\n",
    "df_sinasc['cat_peso_calc'] = [\n",
    "   safe_peso_calc(sexo, peso, semana)\n",
    "   for sexo, peso, semana in zip(\n",
    "       df_sinasc['SEXO'],\n",
    "        df_sinasc['PESO'],\n",
    "        df_sinasc['SEMAGESTAC']\n",
    "   )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc = df_sinasc[\n",
    "    [\n",
    "    'data_nasc'\n",
    "    , 'ano_nasc'\n",
    "    , 'nasc_MUNNOMEX'\n",
    "    , 'res_MUNNOMEX'\n",
    "    , 'nasc_CAPITAL'\n",
    "    , 'res_CAPITAL'\n",
    "    , 'nasc_REGIAO'\n",
    "    , 'res_REGIAO'\n",
    "    , 'nasc_SIGLA_UF'\n",
    "    , 'res_SIGLA_UF'\n",
    "    , 'IDADEMAE'\n",
    "    , 'idademae_faixa'\n",
    "    , 'ESCMAE2010'\n",
    "    , 'escolaridade_mae'\n",
    "    , 'GRAVIDEZ'\n",
    "    , 'tipo_gravidez'\n",
    "    , 'SEMAGESTAC'\n",
    "    , 'idade_gestacao_faixa'\n",
    "    , 'SEXO'\n",
    "    , 'def_sexo'\n",
    "    , 'PESO'\n",
    "    , 'peso_faixa'\n",
    "    , 'cat_peso_calc'\n",
    "    , 'FLAG_BASE'\n",
    "    , 'ESTCIVMAE'\n",
    "    , 'def_est_civil'\n",
    "    , 'RACACOR'\n",
    "    , 'def_raca_cor'\n",
    "    , 'QTDFILMORT'\n",
    "    , 'QTDFILVIVO'\n",
    "    , 'def_paridade'\n",
    "    , 'PARTO'\n",
    "    , 'def_parto'\n",
    "     ]\n",
    " ]\n",
    "   \n",
    "# \n",
    "# df_sinasc.to_csv('base_suja/base_sinasc_suja.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc.to_csv('base_suja/base_sinasc_suja_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'base_suja/base_sinasc_suja_v2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_sinasc \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_suja/base_sinasc_suja_v2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'base_suja/base_sinasc_suja_v2.csv'"
     ]
    }
   ],
   "source": [
    "df_sinasc = pd.read_csv('base_suja/base_sinasc_suja.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration to show more rows and columns\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate data \n",
    "duplicados = df_sinasc.duplicated()\n",
    "soma = duplicados.sum()\n",
    "f\"\"\"The dataset has {soma} duplicate rows, which represents {round((soma/len(df_sinasc)) * 100, 2)} %\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of duplicates by res_SIGLA_UF and ano_evento\n",
    "df_duplicados = df_sinasc[duplicados]\n",
    "df_duplicados.value_counts(['ano_nasc', 'res_SIGLA_UF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting missing values\n",
    "df_sinasc_ = df_sinasc[df_sinasc['FLAG_BASE']=='SINASC']\n",
    "missing_count_sinasc = df_sinasc_.isnull().sum()  # counts the null values in each column\n",
    "missing_percent_sinasc = round((missing_count_sinasc / len(df_sinasc_)) * 100,2)  # calculates the percentage of null values\n",
    "missing_data_sinasc = pd.DataFrame({'Missing Count': missing_count_sinasc, 'Missing Percentage': missing_percent_sinasc})\n",
    "missing_data_sinasc.index.name = 'Variable'  # sets the index name to 'Variable'\n",
    "missing_data_sinasc.reset_index(inplace=True)  # resets the index to make 'Variable' a column\n",
    "missing_data_sinasc['BASE'] = 'SINASC'\n",
    "\n",
    "\n",
    "# Sorting the DataFrame by the highest missing frequencies\n",
    "missing_data_sorted = missing_data_sinasc.sort_values(by=['BASE', 'Missing Count'], ascending=False)\n",
    "missing_data_sorted.to_csv('./EDA/missing_sinasc.csv', index=False)\n",
    "missing_data_sorted[missing_data_sorted['Missing Percentage'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there is any pattern in the missing data looking at year and 'res_SIGLA_UF'\n",
    "lista = [ 'SEMAGESTAC', 'PESO']\n",
    "for i in lista:\n",
    "    print(f\"\"\"Variável {i}\\n\\n{df_sinasc.loc[df_sinasc[i].isnull(), ['FLAG_BASE', 'ano_nasc', 'res_SIGLA_UF']].value_counts()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ignorado = df_sinasc.loc[df_sinasc['SEXO']==0]\n",
    "df_ignorado['FLAG_BASE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variaveis categóricas\n",
    "lista_cat = [\n",
    "'ano_nasc'       \n",
    ", 'nasc_MUNNOMEX'\n",
    ", 'res_MUNNOMEX'\n",
    ", 'nasc_CAPITAL'\n",
    ", 'res_CAPITAL'\n",
    ", 'nasc_REGIAO'\n",
    ", 'res_REGIAO'\n",
    ", 'nasc_SIGLA_UF'\n",
    ", 'res_SIGLA_UF'\n",
    ", 'idademae_faixa'\n",
    ", 'ESCMAE2010'\n",
    ", 'escolaridade_mae'\n",
    ", 'GRAVIDEZ'\n",
    ", 'tipo_gravidez'\n",
    ", 'idade_gestacao_faixa'\n",
    ", 'SEXO'\n",
    ", 'def_sexo'\n",
    ", 'peso_faixa'\n",
    ", 'FLAG_BASE'\n",
    "            ]\n",
    "for col in lista_cat:\n",
    "    print(f'\\nPercentual de valores únicos para {col}:')\n",
    "    print(round((df_sinasc[col].value_counts()/len(df_sinasc)) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Statistics for Numeric Variables\n",
    "lista_numerica = [\n",
    " 'SEMAGESTAC'\n",
    ", 'PESO'\n",
    "]\n",
    "estatisticas_numericas = df_sinasc[lista_numerica].describe()\n",
    "estatisticas_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinasc = df_sinasc.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "def detectar_outliers(col):\n",
    "    q1 = col.quantile(0.25)\n",
    "    q3 = col.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = col[(col < lower_bound) | (col > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "outliers_numericos = df_sinasc[lista_numerica].apply(detectar_outliers)\n",
    "\n",
    "for i in lista_numerica:\n",
    "    print(outliers_numericos.loc[~outliers_numericos[i].isna(), [i]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nascimentos por região por ano\n",
    "pd.crosstab(index=df_sinasc['nasc_REGIAO'], columns=df_sinasc['ano_nasc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sinasc[df_sinasc['SEXO']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sinasc.loc[df_sinasc['idade_gestacao_faixa']=='menor_22'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removendo missings, duplicados e outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_sinasc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicados\n",
    "tam_inicial = len(df_sinasc)\n",
    "df_limpo = df_sinasc.drop_duplicates()\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove duplicates {tam_inicial - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo Missing\n",
    "lista_missing = [\n",
    "    'SEMAGESTAC','PESO', 'nasc_SIGLA_UF'\n",
    "]\n",
    "tam_antes = len(df_limpo)\n",
    "#df_limpo_sim = df_limpo_sim.dropna(subset = lista_missing_sim)\n",
    "df_limpo = df_limpo.dropna(subset = lista_missing)\n",
    "df_limpo = df_limpo.reset_index(drop=True)\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove missing {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['SEXO']!=0]\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove ignored SEXO {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weeks of pregnancy less than 22 are not considered deaths, but rather miscarriages.\n",
    "tam_antes = len(df_limpo)\n",
    "df_limpo = df_limpo.loc[df_limpo['idade_gestacao_faixa']!='menor_22']\n",
    "tam_depois=len(df_limpo)\n",
    "print(f'Remove idade_gestacao_faixa menor_22 {tam_antes - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_inicial = len(df_sinasc)\n",
    "tam_depois = len(df_limpo)\n",
    "print(f'Total remove {tam_inicial - tam_depois} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_limpo = df_limpo.reset_index(drop=True)\n",
    "df_limpo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mortes por região por ano\n",
    "pd.crosstab(index=df_limpo['nasc_REGIAO'], columns=df_limpo['ano_nasc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso calculado, métrica tabela conforme artigo\n",
    "df_limpo['cat_peso_calc'] = [\n",
    "    func_peso_calculado(sexo, peso, int(round(semana_gest, 0))) for sexo, peso, semana_gest in\n",
    "    zip(df_limpo['SEXO'], df_limpo['PESO'], df_limpo['SEMAGESTAC'])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorização pela idade gestacional\n",
    "df_limpo['cat_periodo_nasc'] = ['termo' if sem >= 37 else 'pre_termo' for sem in df_limpo['SEMAGESTAC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Óbitos por região segundo classificação de peso e periodo de nascimento.\n",
    "tabela = pd.crosstab(index=df_limpo['ano_nasc'], columns=[df_limpo['nasc_REGIAO'], df_limpo['cat_peso_calc'], df_limpo['cat_periodo_nasc']])\n",
    "# Converte a tabela para o formato \"long\"\n",
    "tabela_long = tabela.stack(level=[0, 1, 2]).reset_index()\n",
    "\n",
    "# Renomeia as colunas para o formato desejado\n",
    "tabela_long.columns = ['ano', 'regiao', 'adequacao_peso', 'periodo_nasc', 'quantidade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpo.to_csv('base_limpa/base_sinasc_limpa_remocao.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
